# Quick Start Guide (ржмрж╛ржВрж▓рж╛)

## ЁЯЪА ржжрзНрж░рзБржд рж╢рзБрж░рзБ ржХрж░рж╛рж░ ржЙржкрж╛ржпрж╝

### рзз. рж╕рзЗржЯржЖржк ржХрж░рзЛ

```bash
cd text2code-seq2seq

# Dependencies install ржХрж░рзЛ
pip install -r requirements.txt

# NLTK data download ржХрж░рзЛ
python -c "import nltk; nltk.download('punkt')"
```

### рзи. ржкрзНрж░ржержорзЗ Test ржХрж░рзЛ (Optional ржХрж┐ржирзНрждрзБ Recommended)

```bash
python test_models.py
```

ржПржЯрж╛ verify ржХрж░ржмрзЗ ржпрзЗ рж╕ржм models ржарж┐ржХржорждрзЛ ржХрж╛ржЬ ржХрж░ржЫрзЗ ржХрж┐ржирж╛ред

### рзй. Training рж╢рзБрж░рзБ ржХрж░рзЛ

```bash
python train.py
```

ржПржЯрж╛ ржХрж░ржмрзЗ:
- тЬУ CodeSearchNet dataset download ржХрж░ржмрзЗ
- тЬУ рждрж┐ржиржЯрж╛ model train ржХрж░ржмрзЗ (Vanilla RNN, LSTM, LSTM+Attention)
- тЬУ Checkpoints save ржХрж░ржмрзЗ
- тЬУ Loss curves plot ржХрж░ржмрзЗ

**рж╕ржоржпрж╝ рж▓рж╛ржЧржмрзЗ:** CPU рждрзЗ ржкрзНрж░рж╛ржпрж╝ 1-2 ржШржирзНржЯрж╛, GPU рждрзЗ 15-20 ржорж┐ржирж┐ржЯ

### рзк. Evaluation ржХрж░рзЛ

```bash
python evaluate.py
```

ржПржЯрж╛ ржжрзЗржЦрж╛ржмрзЗ:
- тЬУ BLEU Score
- тЬУ Token Accuracy
- тЬУ Exact Match
- тЬУ Error Analysis

### рзл. Attention Visualization ржжрзЗржЦрзЛ

```bash
python visualize_attention.py
```

ржПржЯрж╛ рждрзИрж░рж┐ ржХрж░ржмрзЗ:
- тЬУ Attention heatmaps
- тЬУ ржХрзЛржи docstring word ржХрзЛржи code token attend ржХрж░ржЫрзЗ рждрж╛ ржжрзЗржЦрж╛ржмрзЗ

## ЁЯУБ ржЧрзБрж░рзБрждрзНржмржкрзВрж░рзНржг Files

```
text2code-seq2seq/
тФЬтФАтФА train.py              # тЖР ржПржЯрж╛ ржжрж┐ржпрж╝рзЗ training ржХрж░рзЛ
тФЬтФАтФА evaluate.py           # тЖР ржПржЯрж╛ ржжрж┐ржпрж╝рзЗ evaluation ржХрж░рзЛ
тФЬтФАтФА visualize_attention.py # тЖР ржПржЯрж╛ ржжрж┐ржпрж╝рзЗ attention ржжрзЗржЦрзЛ
тФЬтФАтФА test_models.py        # тЖР ржПржЯрж╛ ржжрж┐ржпрж╝рзЗ test ржХрж░рзЛ
тФВ
тФЬтФАтФА models/
тФВ   тФЬтФАтФА vanilla_rnn.py    # Model 1
тФВ   тФЬтФАтФА lstm_seq2seq.py   # Model 2
тФВ   тФФтФАтФА lstm_attention.py # Model 3
тФВ
тФЬтФАтФА checkpoints/          # тЖР Training ржПрж░ ржкрж░рзЗ ржПржЦрж╛ржирзЗ saves рж╣ржмрзЗ
тФФтФАтФА attention_plots/      # тЖР Visualization ржПржЦрж╛ржирзЗ save рж╣ржмрзЗ
```

## тЪЩя╕П Configuration ржкрж░рж┐ржмрж░рзНрждржи ржХрж░рждрзЗ ржЪрж╛ржЗрж▓рзЗ

`train.py` ржПрж░ `config` dictionary edit ржХрж░рзЛ:

```python
config = {
    'num_train': 10000,      # тЖР Training examples (ржХржорж╛рждрзЗ ржкрж╛рж░рзЛ: 5000)
    'num_epochs': 20,        # тЖР Epochs (ржХржорж╛рждрзЗ ржкрж╛рж░рзЛ: 10)
    'batch_size': 32,        # тЖР Batch size (ржХржорж╛рждрзЗ ржкрж╛рж░рзЛ: 16)
    'learning_rate': 0.001,
    # ...
}
```

## ЁЯОп Assignment ржПрж░ ржЬржирзНржп ржХрзА ржХрзА рж▓рж╛ржЧржмрзЗ

1. тЬЕ рждрж┐ржиржЯрж╛ model trained
2. тЬЕ Training curves (automatically save рж╣ржпрж╝)
3. тЬЕ Evaluation results (JSON files)
4. тЬЕ Attention visualizations (PNG files)
5. тЬЕ Source code (already done!)
6. тЬЕ README (already done!)

## ЁЯРЫ рж╕ржорж╕рзНржпрж╛ рж╣рж▓рзЗ

### Memory рж╢рзЗрж╖ рж╣ржпрж╝рзЗ ржЧрзЗрж▓рзЗ:
```python
# train.py ржП batch_size ржХржорж╛ржУ
'batch_size': 16  # 32 ржПрж░ ржмржжрж▓рзЗ
```

### Dataset download ржирж╛ рж╣рж▓рзЗ:
```bash
# Cache clear ржХрж░рзЛ
rm -rf ~/.cache/huggingface/datasets
python train.py
```

### Import error рж╣рж▓рзЗ:
```bash
pip install -r requirements.txt --force-reinstall
```

## ЁЯУК Expected Results

| Model | BLEU | Token Acc | Exact Match |
|-------|------|-----------|-------------|
| Vanilla RNN | ~20 | ~45% | ~8% |
| LSTM | ~35 | ~60% | ~18% |
| LSTM + Attention | ~50 | ~75% | ~30% |

## ЁЯТб Tips

1. ржкрзНрж░ржержорзЗ **test_models.py** run ржХрж░рзЛ - ржПржЯрж╛ ржирж┐рж╢рзНржЪрж┐ржд ржХрж░ржмрзЗ рж╕ржм ржарж┐ржХ ржЖржЫрзЗ
2. Training ржП **GPU** use ржХрж░рж▓рзЗ ржЕржирзЗржХ faster рж╣ржмрзЗ
3. Smaller dataset ржжрж┐ржпрж╝рзЗ рж╢рзБрж░рзБ ржХрж░рзЛ (5000 examples), ржкрж░рзЗ ржмрж╛ржбрж╝рж╛ржУ
4. Checkpoints **save** рж╣ржпрж╝ automatically - ржорж╛ржЭрзЗ training stop ржХрж░рж▓рзЗржУ problem ржирзЗржЗ

## ЁЯОУ ржХрзА рж╢рж┐ржЦржмрзЗ

- тЬЕ RNN vs LSTM vs Attention ржПрж░ practical difference
- тЬЕ Seq2Seq architecture implementation
- тЬЕ PyTorch training loop
- тЬЕ Evaluation metrics (BLEU, accuracy)
- тЬЕ Attention mechanism visualization
- тЬЕ Real-world NLP task handling

---

**рж╢рзБржнржХрж╛ржоржирж╛! ЁЯЪА**

ржХрзЛржи ржкрзНрж░рж╢рзНржи ржерж╛ржХрж▓рзЗ README.md ржжрзЗржЦрзЛ ржмрж╛ code ржП comments ржкржбрж╝рзЛред
